{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6baf423-bb24-4b9e-853c-95db6c6fbcb1",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "021d56a3-a047-4dca-bee6-19fafca5f332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyLDAvis\n",
      "  Downloading pyLDAvis-3.4.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: numpy>=1.24.2 in c:\\users\\owner\\anaconda3\\envs\\datascience\\lib\\site-packages (from pyLDAvis) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\owner\\anaconda3\\envs\\datascience\\lib\\site-packages (from pyLDAvis) (1.10.0)\n",
      "Requirement already satisfied: pandas>=2.0.0 in c:\\users\\owner\\anaconda3\\envs\\datascience\\lib\\site-packages (from pyLDAvis) (2.2.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\owner\\anaconda3\\envs\\datascience\\lib\\site-packages (from pyLDAvis) (1.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\owner\\anaconda3\\envs\\datascience\\lib\\site-packages (from pyLDAvis) (3.1.3)\n",
      "Requirement already satisfied: numexpr in c:\\users\\owner\\anaconda3\\envs\\datascience\\lib\\site-packages (from pyLDAvis) (2.8.4)\n",
      "Collecting funcy (from pyLDAvis)\n",
      "  Downloading funcy-2.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\owner\\anaconda3\\envs\\datascience\\lib\\site-packages (from pyLDAvis) (1.1.3)\n",
      "Collecting gensim (from pyLDAvis)\n",
      "  Downloading gensim-4.3.2-cp311-cp311-win_amd64.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\owner\\anaconda3\\envs\\datascience\\lib\\site-packages (from pyLDAvis) (68.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\owner\\anaconda3\\envs\\datascience\\lib\\site-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\owner\\anaconda3\\envs\\datascience\\lib\\site-packages (from pandas>=2.0.0->pyLDAvis) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\owner\\anaconda3\\envs\\datascience\\lib\\site-packages (from pandas>=2.0.0->pyLDAvis) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\owner\\anaconda3\\envs\\datascience\\lib\\site-packages (from scikit-learn>=1.0.0->pyLDAvis) (2.2.0)\n",
      "Collecting smart-open>=1.8.1 (from gensim->pyLDAvis)\n",
      "  Downloading smart_open-7.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\owner\\anaconda3\\envs\\datascience\\lib\\site-packages (from jinja2->pyLDAvis) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\owner\\anaconda3\\envs\\datascience\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\owner\\anaconda3\\envs\\datascience\\lib\\site-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.14.1)\n",
      "Downloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.6 MB 991.0 kB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.2/2.6 MB 2.8 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.5/2.6 MB 4.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.0/2.6 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.1/2.6 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.1/2.6 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.6/2.6 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.7/2.6 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.1/2.6 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 5.9 MB/s eta 0:00:00\n",
      "Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gensim-4.3.2-cp311-cp311-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.4/24.0 MB 10.9 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.9/24.0 MB 11.0 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.2/24.0 MB 9.6 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.6/24.0 MB 9.3 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 2.1/24.0 MB 10.3 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 2.6/24.0 MB 9.9 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.3/24.0 MB 10.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 3.8/24.0 MB 10.9 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 4.2/24.0 MB 10.8 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 4.4/24.0 MB 9.8 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 5.0/24.0 MB 10.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 5.5/24.0 MB 10.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 6.0/24.0 MB 10.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 6.4/24.0 MB 10.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 6.7/24.0 MB 9.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 7.5/24.0 MB 10.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 7.5/24.0 MB 9.8 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 8.1/24.0 MB 9.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 8.9/24.0 MB 10.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 9.3/24.0 MB 10.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 10.0/24.0 MB 10.3 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 10.4/24.0 MB 10.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 11.2/24.0 MB 10.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 11.6/24.0 MB 10.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 11.7/24.0 MB 10.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 12.3/24.0 MB 10.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 12.5/24.0 MB 10.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 13.2/24.0 MB 10.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 14.0/24.0 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 15.0/24.0 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 15.5/24.0 MB 11.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 15.7/24.0 MB 10.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 15.9/24.0 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 16.4/24.0 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 16.6/24.0 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 16.7/24.0 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 17.0/24.0 MB 10.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 17.7/24.0 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 18.2/24.0 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 18.8/24.0 MB 10.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 19.9/24.0 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 20.6/24.0 MB 10.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.4/24.0 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 21.6/24.0 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.1/24.0 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.5/24.0 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.5/24.0 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.8/24.0 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.0 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 10.4 MB/s eta 0:00:00\n",
      "Downloading smart_open-7.0.1-py3-none-any.whl (60 kB)\n",
      "   ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 60.8/60.8 kB 3.2 MB/s eta 0:00:00\n",
      "Installing collected packages: funcy, smart-open, gensim, pyLDAvis\n",
      "Successfully installed funcy-2.0 gensim-4.3.2 pyLDAvis-3.4.1 smart-open-7.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_225180\\56450832.py:8: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  wdm = pd.read_csv('../data/wdms/count/worldnewsapi/lemmed/text.csv',index_col=0).iloc[:,4:100].astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>said</th>\n",
       "      <th>transgender</th>\n",
       "      <th>people</th>\n",
       "      <th>woman</th>\n",
       "      <th>school</th>\n",
       "      <th>gender</th>\n",
       "      <th>year</th>\n",
       "      <th>trans</th>\n",
       "      <th>state</th>\n",
       "      <th>child</th>\n",
       "      <th>...</th>\n",
       "      <th>place</th>\n",
       "      <th>house</th>\n",
       "      <th>saying</th>\n",
       "      <th>home</th>\n",
       "      <th>added</th>\n",
       "      <th>thing</th>\n",
       "      <th>legal</th>\n",
       "      <th>judge</th>\n",
       "      <th>minor</th>\n",
       "      <th>kid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   said  transgender  people  woman  school  gender  year  trans  state  \\\n",
       "0     0           46       0      0       0       0     2      0      0   \n",
       "1     0           38       9      6       0      15     6      7      0   \n",
       "2     0           36      21      0       0       2     2      0      0   \n",
       "3     5           31       2      0      12      12    10      0     19   \n",
       "4     0           35      35      1       0       0     0      0      0   \n",
       "\n",
       "   child  ...  place  house  saying  home  added  thing  legal  judge  minor  \\\n",
       "0      0  ...      0      0       1     0      0      0      0     22      0   \n",
       "1      1  ...      0      0       1     0      0      0     14      0      0   \n",
       "2      1  ...      0      0       0     0      0      0      0      0      0   \n",
       "3      8  ...      0      0       0     0      3      0      0      0      1   \n",
       "4      0  ...      0      0       0     0      0      0      0      0      0   \n",
       "\n",
       "   kid  \n",
       "0    0  \n",
       "1    0  \n",
       "2    0  \n",
       "3    1  \n",
       "4    0  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import functions and load data\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyLDAvis\n",
    "import pyLDAvis.lda_model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "wdm = pd.read_csv('../data/wdms/count/worldnewsapi/lemmed/text.csv',index_col=0).iloc[:,4:100].astype(int)\n",
    "wdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "453b3b12-38e4-4e29-bc98-a5a44b9b0c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIZE:  (3101, 7)\n"
     ]
    }
   ],
   "source": [
    "num_topics = 2\n",
    "\n",
    "lda_model_DH = LatentDirichletAllocation(n_components=num_topics, \n",
    "                                         max_iter=100, learning_method='online')\n",
    "LDA_DH_Model = lda_model_DH.fit_transform(wdm)\n",
    "\n",
    "\n",
    "print(\"SIZE: \", LDA_DH_Model.shape)  # (NO_DOCUMENTS, NO_TOPICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "717abfd9-d585-4726-9d25-168b13fbad5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First headline...\n",
      "[2.51363031e-04 2.51279955e-04 7.88131612e-02 2.51163353e-04\n",
      " 2.51186958e-04 9.19930341e-01 2.51504740e-04]\n",
      "Sixth headline...\n",
      "[5.14224296e-01 2.34106094e-04 2.30262082e-01 2.34346308e-04\n",
      " 7.09430470e-03 1.21150626e-02 2.35835802e-01]\n"
     ]
    }
   ],
   "source": [
    "# Let's see how the first document in the corpus looks like in\n",
    "## different topic spaces\n",
    "print(\"First headline...\")\n",
    "print(LDA_DH_Model[0])\n",
    "print(\"Sixth headline...\")\n",
    "print(LDA_DH_Model[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d0615d-cfcb-47ce-b90d-ec950990daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(lda_model_DH.components_)\n",
    "\n",
    "\n",
    "## implement a print function \n",
    "## REF: https://nlpforhackers.io/topic-modeling/\n",
    "def print_topics(model, vectorizer, top_n=10):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic:  \", idx)\n",
    "      \n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-top_n - 1:-1]])\n",
    "                        ## gets top n elements in decreasing order\n",
    "    \n",
    "\n",
    "####### call the function above with our model and CountV\n",
    "print_topics(lda_model_DH, MyCountV, 15)\n",
    "\n",
    "\n",
    "\n",
    "## Print LDA using print function from above\n",
    "########## Other Notes ####################\n",
    "#import pyLDAvis.sklearn as LDAvis\n",
    "#import pyLDAvis\n",
    "#import pyLDAvis.gensim \n",
    "## conda install -c conda-forge pyldavis\n",
    "#pyLDAvis.enable_notebook() ## not using notebook\n",
    "#panel = LDAvis.prepare(lda_model_DH, MyDTM_DF, MyCountV, mds='tsne')\n",
    "#pyLDAvis.show(panel)\n",
    "#panel = pyLDAvis.gensim.prepare(lda_model_DH, MyDTM, MyCountV, mds='tsne')\n",
    "#pyLDAvis.show(panel)\n",
    "##########################################################################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "word_topic = np.array(lda_model_DH.components_)\n",
    "#print(word_topic)\n",
    "word_topic = word_topic.transpose()\n",
    "\n",
    "num_top_words = 15\n",
    "vocab_array = np.asarray(vocab)\n",
    "\n",
    "#fontsize_base = 70 / np.max(word_topic) # font size for word with largest share in corpus\n",
    "fontsize_base = 20\n",
    "\n",
    "for t in range(num_topics):\n",
    "    plt.subplot(1, num_topics, t + 1)  # plot numbering starts with 1\n",
    "    plt.ylim(0, num_top_words + 0.5)  # stretch the y-axis to accommodate the words\n",
    "    plt.xticks([])  # remove x-axis markings ('ticks')\n",
    "    plt.yticks([]) # remove y-axis markings ('ticks')\n",
    "    plt.title('Topic #{}'.format(t))\n",
    "    top_words_idx = np.argsort(word_topic[:,t])[::-1]  # descending order\n",
    "    top_words_idx = top_words_idx[:num_top_words]\n",
    "    top_words = vocab_array[top_words_idx]\n",
    "    top_words_shares = word_topic[top_words_idx, t]\n",
    "    for i, (word, share) in enumerate(zip(top_words, top_words_shares)):\n",
    "        plt.text(0.3, num_top_words-i-0.5, word, fontsize=fontsize_base)\n",
    "                 ##fontsize_base*share)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
