{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "269aa357-0753-47af-bb39-d75c86bbbf89",
   "metadata": {},
   "source": [
    "# Association Rule Mining\n",
    "\n",
    "Association Rule Mining (ARM) is an analysis tool for finding out if certain items in a dataset 'go together'-- i.e. if they are often seen next to each other in an observation. ARM is on 'transaction datasets', datasets where each observation is treated as a group of items. Transaction datasets are similar to word-document matrices, but with some key distinctions. In transaction datasets:\n",
    "\n",
    "    1. Order of items doesn't matter.\n",
    "    2. Frequency of items also doesn't matter, with the exception of 0.\n",
    "\n",
    "In transaction data, each document is considered a set of words, where either a word is present in the document or it isn't. How often a word appears isn't relevant in this data. To perform ARM analysis on my text data, I'll first have to convert it to a transactional dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a59030-6e8a-4538-86b3-b99177dc2ffa",
   "metadata": {},
   "source": [
    "# Converting my data to transactional data.\n",
    "\n",
    "To start, I'm going to transform my WDM into a transactional data format, so I can perform ARM on it. I'm going to perform this analysis on the title dataset from WorldNewsAPI, as I think that there could be some interesting relationships revealed from the small batch of words contained within the article titles.\n",
    "\n",
    "Here's my python code for doing this. Since I can't support python and R in one notebook, I'll just display it, but I won't run it here. You can see the result of the code in the `transactions` object being read in afterwards.\n",
    "ws_title.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989871e4-8c53-461e-b3ec-a7484e2e2299",
   "metadata": {},
   "source": [
    "### Python Code for creating transaction data\n",
    "```\n",
    "import pandas as pd\n",
    "\n",
    "wdm = pd.read_csv('data/wdms/count/worldnewsapi/lemmed/title.csv',index_col=0)\n",
    "\n",
    "basket_df = pd.DataFrame(columns=['transactions'])\n",
    "for i in range(len(wdm)):\n",
    "    terms=wdm.iloc[i,4:].astype(int)\n",
    "    # For each row, filter that row by x>0, i.e. there is at least one instance of that term in the document.\n",
    "    filter=terms.apply(lambda x:x>0)\n",
    "    terms=terms[filter]\n",
    "    # Then turn the index of the resulting series into a comma separated list to get the basket of terms.\n",
    "    basket = ' '.join(list(terms.index))\n",
    "    basket_df.loc[len(basket_df.index)]=basket\n",
    "\n",
    "basket_df.to_csv('data/transaction/worldnews_title.csv')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbb337bf-81c5-4734-b428-da1fbe12bd39",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in read.transactions(\"../data/transaction/worldnews_title.csv\", : could not find function \"read.transactions\"\n",
     "output_type": "error",
     "traceback": [
      "Error in read.transactions(\"../data/transaction/worldnews_title.csv\", : could not find function \"read.transactions\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "install.packages('arules')\n",
    "#Reading the transaction data into R with read.transactions\n",
    "transactions <- read.transactions('../data/transaction/worldnews_title.csv',format='basket',row.names=1)\n",
    "head(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d927c6-4f61-4c04-bb4c-035e37d51e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
