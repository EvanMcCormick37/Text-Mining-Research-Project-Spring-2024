{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25c346d3",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "So, now I have a bunch of text relating to transgender events in the News. How can I turn this text into data I can easily analyze? The first step is cleaning it up into a cleaned corpus by removing junk words, and turning the relevant words into easier-to-work-with forms. Then I can transform the cleaned corpi into word-document matrices for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f706b021",
   "metadata": {},
   "source": [
    "# Cleaning the API Corpi\n",
    "\n",
    "I went through a couple of iterations of a pipeline to turn the NewsAPI and WorldNewsAPI documents into cleaned corpi. \n",
    "Initially, I made four pipelines, one for each API, and one using PorterStemmer with one using WordNetLemmatizer. This was a massive waste of space, as I quickly realized I could place both the stemmed and lemmed versions of the text into separate columns of a single .csv file.\n",
    "\n",
    "I also realized that I was using the same basic algorithm to clean every text column in each of these APIs, with the only distinction being the column name. Thus, I combined all of the API data into a single pipeline which cleaned every text column and returned a stemmed/lemmed version of said columns. Then I was able to combine these columns into complete cleaned corpi for each API dataset.\n",
    "\n",
    "Here is that pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8a20880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>authors</th>\n",
       "      <th>country</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>url</th>\n",
       "      <th>text_s</th>\n",
       "      <th>text_l</th>\n",
       "      <th>title_s</th>\n",
       "      <th>title_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>Russia’s Supreme Court effectively outlaws LGB...</td>\n",
       "      <td>Menu Menu World U.S. Politics Sports Entertain...</td>\n",
       "      <td>DASHA LITVINOVA</td>\n",
       "      <td>us</td>\n",
       "      <td>0.311</td>\n",
       "      <td>https://apnews.com/article/russia-lgbtq-crackd...</td>\n",
       "      <td>menu menu world us polit sport entertain busi ...</td>\n",
       "      <td>Menu Menu World US Politics Sports Entertainme...</td>\n",
       "      <td>russia suprem court effect outlaw lgbtq activ ...</td>\n",
       "      <td>Russias Supreme Court effectively outlaw LGBTQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>Where Do Trans Rights Stand in Taiwan After Sa...</td>\n",
       "      <td>An estimated 5,000 people gathered in Ximendin...</td>\n",
       "      <td>Daniel Yo-Ling</td>\n",
       "      <td>us</td>\n",
       "      <td>0.134</td>\n",
       "      <td>https://thediplomat.com/2023/11/where-do-trans...</td>\n",
       "      <td>an estim 5000 peopl gather in ximend on the ev...</td>\n",
       "      <td>An estimated 5000 people gathered in Ximending...</td>\n",
       "      <td>where do tran right stand in taiwan after same...</td>\n",
       "      <td>Where Do Trans Rights Stand in Taiwan After Sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>Transgender People&amp;#039;s Neurological Needs A...</td>\n",
       "      <td>As a transgender neurologist, I advocate for t...</td>\n",
       "      <td>Deneen Broadnax</td>\n",
       "      <td>us</td>\n",
       "      <td>0.12</td>\n",
       "      <td>https://worldnewsera.com/news/science/transgen...</td>\n",
       "      <td>as a transgend neurologist i advoc for the imp...</td>\n",
       "      <td>As a transgender neurologist I advocate for th...</td>\n",
       "      <td>transgend people039 neurolog need are be overl...</td>\n",
       "      <td>Transgender People039s Neurological Needs Are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>Class 10th, 12th Board Exams Forms: Transgende...</td>\n",
       "      <td>After the Supreme Court recognised transgender...</td>\n",
       "      <td>Deeksha Teri</td>\n",
       "      <td>in</td>\n",
       "      <td>0.06</td>\n",
       "      <td>https://indianexpress.com/article/education/cl...</td>\n",
       "      <td>after the suprem court recognis transgend peop...</td>\n",
       "      <td>After the Supreme Court recognised transgender...</td>\n",
       "      <td>class 10th 12th board exam form transgend stud...</td>\n",
       "      <td>Class 10th 12th Board Exams Forms Transgender ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>Photos: Protesters squared off in downtown Ottawa</td>\n",
       "      <td>Article content PHOTO GALLERY Thousands of peo...</td>\n",
       "      <td>Lois Kirkup</td>\n",
       "      <td>ca</td>\n",
       "      <td>0.481</td>\n",
       "      <td>https://ottawacitizen.com/news/local-news/phot...</td>\n",
       "      <td>articl content photo galleri thousand of peopl...</td>\n",
       "      <td>Article content PHOTO GALLERY Thousands of peo...</td>\n",
       "      <td>photo protest squar off in downtown ottawa</td>\n",
       "      <td>Photos Protesters squared off in downtown Ottawa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0.0  Russia’s Supreme Court effectively outlaws LGB...   \n",
       "1.0  Where Do Trans Rights Stand in Taiwan After Sa...   \n",
       "2.0  Transgender People&#039;s Neurological Needs A...   \n",
       "3.0  Class 10th, 12th Board Exams Forms: Transgende...   \n",
       "4.0  Photos: Protesters squared off in downtown Ottawa   \n",
       "\n",
       "                                                  text          authors  \\\n",
       "0.0  Menu Menu World U.S. Politics Sports Entertain...  DASHA LITVINOVA   \n",
       "1.0  An estimated 5,000 people gathered in Ximendin...   Daniel Yo-Ling   \n",
       "2.0  As a transgender neurologist, I advocate for t...  Deneen Broadnax   \n",
       "3.0  After the Supreme Court recognised transgender...     Deeksha Teri   \n",
       "4.0  Article content PHOTO GALLERY Thousands of peo...      Lois Kirkup   \n",
       "\n",
       "    country sentiment                                                url  \\\n",
       "0.0      us     0.311  https://apnews.com/article/russia-lgbtq-crackd...   \n",
       "1.0      us     0.134  https://thediplomat.com/2023/11/where-do-trans...   \n",
       "2.0      us      0.12  https://worldnewsera.com/news/science/transgen...   \n",
       "3.0      in      0.06  https://indianexpress.com/article/education/cl...   \n",
       "4.0      ca     0.481  https://ottawacitizen.com/news/local-news/phot...   \n",
       "\n",
       "                                                text_s  \\\n",
       "0.0  menu menu world us polit sport entertain busi ...   \n",
       "1.0  an estim 5000 peopl gather in ximend on the ev...   \n",
       "2.0  as a transgend neurologist i advoc for the imp...   \n",
       "3.0  after the suprem court recognis transgend peop...   \n",
       "4.0  articl content photo galleri thousand of peopl...   \n",
       "\n",
       "                                                text_l  \\\n",
       "0.0  Menu Menu World US Politics Sports Entertainme...   \n",
       "1.0  An estimated 5000 people gathered in Ximending...   \n",
       "2.0  As a transgender neurologist I advocate for th...   \n",
       "3.0  After the Supreme Court recognised transgender...   \n",
       "4.0  Article content PHOTO GALLERY Thousands of peo...   \n",
       "\n",
       "                                               title_s  \\\n",
       "0.0  russia suprem court effect outlaw lgbtq activ ...   \n",
       "1.0  where do tran right stand in taiwan after same...   \n",
       "2.0  transgend people039 neurolog need are be overl...   \n",
       "3.0  class 10th 12th board exam form transgend stud...   \n",
       "4.0         photo protest squar off in downtown ottawa   \n",
       "\n",
       "                                               title_l  \n",
       "0.0  Russias Supreme Court effectively outlaw LGBTQ...  \n",
       "1.0  Where Do Trans Rights Stand in Taiwan After Sa...  \n",
       "2.0  Transgender People039s Neurological Needs Are ...  \n",
       "3.0  Class 10th 12th Board Exams Forms Transgender ...  \n",
       "4.0   Photos Protesters squared off in downtown Ottawa  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Regular Expressions will come in handy here.\n",
    "import re\n",
    "#Importing the WordNetLemmatizer and the PorterStemmer from NLTK for stemming and lemming\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "news = pd.read_csv('../data/newsapi_corpus_raw.csv',index_col=0)\n",
    "world_news = pd.read_csv('../data/worldnewsapi_corpus_raw.csv',index_col=0)\n",
    "\n",
    "#Here I create some object for later. A porterStemmer, WordNetLemmatizer, and lastly a 'junk' regex which will help me remove garbage characters from the text.\n",
    "wnl = WordNetLemmatizer()\n",
    "ps = PorterStemmer()\n",
    "#(This is a regex for anything that isn't alphanumeric)\n",
    "junk = re.compile('[^a-zA-Z\\\\d]')\n",
    "\n",
    "#Split the text along white-space and remove junk, then lemmatize\n",
    "def lemmatize(text):\n",
    "    #I tried splitting along a few differend regexes here, but ultimately the whitespace literal proved the best.\n",
    "    word_list = re.split(' ',text)\n",
    "    #This line removes all junk characters (anything non-alphanumeric) from each word in the list.\n",
    "    word_list = [re.sub(junk,'',word) for word in word_list]\n",
    "    word_list = [wnl.lemmatize(word) for word in word_list]\n",
    "    return ' '.join(word_list)\n",
    "v_lemm = np.vectorize(lemmatize)\n",
    "\n",
    "#Same process but with the PorterStemmer rather than the WordNetLemmatizer\n",
    "def stem(text):\n",
    "    word_list = re.split(' ',text)\n",
    "    word_list = word_list = [re.sub(junk,'',word) for word in word_list]\n",
    "    word_list = [ps.stem(word) for word in word_list]\n",
    "    return ' '.join(word_list)\n",
    "v_stem = np.vectorize(stem)\n",
    "#Fill nan values\n",
    "news = news.fillna('')\n",
    "world_news = world_news.fillna('')\n",
    "\n",
    "# I did this already, now commenting it out for ease of use for stemming.\n",
    "\n",
    "#Add stemmed and lemmed versions of News as columns\n",
    "news.loc[:,'title_s']=v_stem(news.loc[:,'title'])\n",
    "news.loc[:,'desc_s']=v_stem(news.loc[:,'description'])\n",
    "news.loc[:,'content_s']=v_stem(news.loc[:,'content'])\n",
    "news.loc[:,'title_l']=v_lemm(news.loc[:,'title'])\n",
    "news.loc[:,'desc_l']=v_lemm(news.loc[:,'description'])\n",
    "news.loc[:,'content_l']=v_lemm(news.loc[:,'content'])\n",
    "\n",
    "#Do the same for world_news\n",
    "world_news.loc[:,'text_s']=v_stem(world_news.loc[:,'text'])\n",
    "world_news.loc[:,'text_l']=v_lemm(world_news.loc[:,'text'])\n",
    "world_news.loc[:,'title_s']=v_stem(world_news.loc[:,'title'])\n",
    "world_news.loc[:,'title_l']=v_lemm(world_news.loc[:,'title'])\n",
    "\n",
    "#news.to_csv('../../data/newsapi_corpus_cleaned.csv',index=0)\n",
    "#world_news.to_csv('../../data/worldnewsapi_corpus_cleaned.csv',index=0)\n",
    "news.head()\n",
    "world_news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3e2c37",
   "metadata": {},
   "source": [
    "# Ground News\n",
    "\n",
    "For this dataset, I wanted to do more than just stem and lem each word. I knew the source_text entries contained a lot of junk words which came from advertisements, site descriptions, subscription requests, etc. I wanted to remove as much of this junk text as I could while keeping the text relevant to the news story. \n",
    "\n",
    "To do this, I took advantage of the fact that the source text retained its original order, and that I had a **title** entry corresponding to each **source_text** entry. The plan was to tokenize and lemmatize the title and corresponding source text entry, then only keep the words in the source text which came in between the first and last word which matched a word in the title.\n",
    "\n",
    "### Example:\n",
    "Using the title\n",
    "\n",
    "**'Greece Legalizes same-sex marriage'**\n",
    "\n",
    "and this monster lemmatized source text:\n",
    "\n",
    "   ```\n",
    "   \"BBC HomepageSkip to contentAccessibility HelpYour accountHomeNewsSportEarthReelWorklifeTravelMore menuMore menuSearch BBCHomeNewsSportEarthReelWorklifeTravelCultureFutureMusicTVWeatherSoundsClose menuBBC NewsMenuHomeIsrael-Gaza warWar in UkraineClimateVideoWorldUS & CanadaUKBusinessTechMoreScienceEntertainment & ArtsHealthIn PicturesBBC VerifyWorld News TVNewsbeatWorldAfricaAsiaAustraliaEuropeLatin AmericaMiddle EastGreece legalises same-sex marriagePublished1 day agoShareclose panelShare pageCopy linkAbout sharingThis video can not be playedTo play this video you need to enable JavaScript in your browser.Media caption, Watch: Cheers in Athens as same-sex marriage becomes lawBy James GregoryBBC NewsGreece has become the first Christian Orthodox-majority country to legalise same-sex marriage.Same-sex couples will now also be legally allowed to adopt children after Thursday's 176-76 vote in parliament.Prime Minister Kyriakos Mitsotakis said the new law would \"\"boldly abolish a serious inequality\"\".But it has divided the country, with fierce resistance led by the powerful Orthodox Church. Its supporters held a protest rally in Athens.Many displayed banners, held crosses, read prayers and sang passages from the Bible in the capital's Syntagma Square.The head of the Orthodox Church, Archbishop Ieronymos, said the measure would \"\"corrupt the homeland's social cohesion\"\".The bill needed a simple majority to pass through the 300-member parliament.Mr Mitsotakis had championed the bill but required the support of opposition parties to get it over the line, with dozens of MPs from his centre-right governing party opposed. \"\"People who have been invisible will finally be made visible around us, and with them, many children will finally find their rightful place,\"\" the prime minister told parliament during a debate ahead of the vote. \"\"The reform makes the lives of several of our fellow citizens better, without taking away anything from the lives of the many.\"\"Image source, Getty ImagesImage caption, Opponents of the legislature held a protest rally in front of the parliament building in AthensThe vote has been welcomed by LGBTQ organisations in Greece.\"\"This is a historic moment,\"\" Stella Belia, the head of same-sex parents' group Rainbow Families, told Reuters news agency. \"\"This is a day of joy.\"\" Fifteen of the European Union's 27 members have already legalised same-sex marriage. It is permitted in 35 countries worldwide.Greece has until now lagged behind some of its European neighbours, largely because of opposition from the Church. It is the first country in south-eastern Europe to have marriage equality.Related TopicsGreeceMarriageLGBTMore on this storyCheers in Athens as same-sex marriage becomes law. Video, 00:00:28Cheers in Athens as same-sex marriage becomes lawPublished1 day ago0:28Top StoriesLive. ‘Putin is responsible’ - Biden speaks out after report of Navalny’s deathTrump ordered to pay 354m in New York fraud casePublished10 hours agoTrump must pay 354m. How could he do it?Published2 hours agoFeaturesAlexei Navalny: What we know about reports of his deathNavalny’s life in 'Polar Wolf' remote penal colonyArrested and poisoned: See Navalny's moments of defiance. VideoArrested and poisoned: See Navalny's moments of defianceSatellite images show construction on Egypt-Gaza borderIs Russia about to win another victory in Ukraine?The Argentines backing a 'crazy' president's shock therapyMillions of donkeys killed each year to make medicineWeekly quiz: Who could join Sinéad in the Rock & Roll Hall of Fame?The KGB spy who rubbed shoulders with French elite for decadesElsewhere on the BBCWhy Gen Z are dressing like Mob WivesThe world map created by a man who never left homeThe seedy underbelly of life coachingMost Read1Amy Schumer hits back at comments about her face2Two teenagers charged over Super Bowl parade shooting3Alexei Navalny: What we know about reports of his death4King's cancer may bring family closer, says Harry5Brian Wilson's family seeks conservatorship6Trump must pay 354m. How could he do it?7Satellite images show construction on Egypt-Gaza border8Fani Willis' dad testifies in Trump Georgia case9Democrats relieved as Manchin rules out White House bid10Biden condemns House recess without new Ukraine aidBBC News ServicesOn your mobileOn smart speakersGet news alertsContact BBC NewsHomeNewsSportEarthReelWorklifeTravelCultureFutureMusicTVWeatherSoundsTerms of UseAbout the BBCPrivacy PolicyCookiesAccessibility HelpParental GuidanceContact the BBCGet Personalised NewslettersWhy you can trust the BBCAdvertise with us© 2024 BBC. The BBC is not responsible for the content of external sites. Read about our approach to external linking.\"\n",
    "```\n",
    "\n",
    "This algorithm will throw out a bunch of junk at the beginning and end, and only keep the bulk of the article, which falls in between two instances of words which match their lemmatized cousins in the corresponding **title** entry.\n",
    "\n",
    "  ~~BBC HomepageSkip to contentAccessibility HelpYour accountHomeNewsSportEarthReelWorklifeTravelMore menuMore menuSearch BBCHomeNewsSportEarthReelWorklifeTravelCultureFutureMusicTVWeatherSoundsClose menuBBC NewsMenuHomeIsrael-Gaza warWar in UkraineClimateVideoWorldUS & CanadaUKBusinessTechMoreScienceEntertainment & ArtsHealthIn PicturesBBC VerifyWorld News TVNewsbeatWorldAfricaAsiaAustraliaEuropeLatin AmericaMiddle EastGreece~~ \n",
    "  ```\n",
    "  legalises same-sex marriagePublished1 day agoShareclose panelShare pageCopy linkAbout sharingThis video can not be playedTo play this video you need to enable JavaScript in your browser.Media caption, Watch: Cheers in Athens as same-sex marriage becomes lawBy James GregoryBBC NewsGreece has become the first Christian Orthodox-majority country to legalise same-sex marriage.Same-sex couples will now also be legally allowed to adopt children after Thursday's 176-76 vote in parliament.Prime Minister Kyriakos Mitsotakis said the new law would \"\"boldly abolish a serious inequality\"\".But it has divided the country, with fierce resistance led by the powerful Orthodox Church. Its supporters held a protest rally in Athens.Many displayed banners, held crosses, read prayers and sang passages from the Bible in the capital's Syntagma Square.The head of the Orthodox Church, Archbishop Ieronymos, said the measure would \"\"corrupt the homeland's social cohesion\"\".The bill needed a simple majority to pass through the 300-member parliament.Mr Mitsotakis had championed the bill but required the support of opposition parties to get it over the line, with dozens of MPs from his centre-right governing party opposed. \"\"People who have been invisible will finally be made visible around us, and with them, many children will finally find their rightful place,\"\" the prime minister told parliament during a debate ahead of the vote. \"\"The reform makes the lives of several of our fellow citizens better, without taking away anything from the lives of the many.\"\"Image source, Getty ImagesImage caption, Opponents of the legislature held a protest rally in front of the parliament building in AthensThe vote has been welcomed by LGBTQ organisations in Greece.\"\"This is a historic moment,\"\" Stella Belia, the head of same-sex parents' group Rainbow Families, told Reuters news agency. \"\"This is a day of joy.\"\" Fifteen of the European Union's 27 members have already legalised same-sex marriage. It is permitted in 35 countries worldwide.Greece has until now lagged behind some of its European neighbours, largely because of opposition from the Church. It is the first country in south-eastern Europe to have marriage\n",
    "  ```\n",
    "  ~~equality.Related TopicsGreeceMarriageLGBTMore on this storyCheers in Athens as same-sex marriage becomes law. Video, 00:00:28Cheers in Athens as same-sex marriage becomes lawPublished1 day ago0:28Top StoriesLive. ‘Putin is responsible’ - Biden speaks out after report of Navalny’s deathTrump ordered to pay 354m in New York fraud casePublished10 hours agoTrump must pay 354m. How could he do it?Published2 hours agoFeaturesAlexei Navalny: What we know about reports of his deathNavalny’s life in 'Polar Wolf' remote penal colonyArrested and poisoned: See Navalny's moments of defiance. VideoArrested and poisoned: See Navalny's moments of defianceSatellite images show construction on Egypt-Gaza borderIs Russia about to win another victory in Ukraine?The Argentines backing a 'crazy' president's shock therapyMillions of donkeys killed each year to make medicineWeekly quiz: Who could join Sinéad in the Rock & Roll Hall of Fame?The KGB spy who rubbed shoulders with French elite for decadesElsewhere on the BBCWhy Gen Z are dressing like Mob WivesThe world map created by a man who never left homeThe seedy underbelly of life coachingMost Read1Amy Schumer hits back at comments about her face2Two teenagers charged over Super Bowl parade shooting3Alexei Navalny: What we know about reports of his death4King's cancer may bring family closer, says Harry5Brian Wilson's family seeks conservatorship6Trump must pay 354m. How could he do it?7Satellite images show construction on Egypt-Gaza border8Fani Willis' dad testifies in Trump Georgia case9Democrats relieved as Manchin rules out White House bid10Biden condemns House recess without new Ukraine aidBBC News ServicesOn your mobileOn smart speakersGet news alertsContact BBC NewsHomeNewsSportEarthReelWorklifeTravelCultureFutureMusicTVWeatherSoundsTerms of UseAbout the BBCPrivacy PolicyCookiesAccessibility HelpParental GuidanceContact the BBCGet Personalised NewslettersWhy you can trust the BBCAdvertise with us© 2024 BBC. The BBC is not responsible for the content of external sites. Read about our approach to external linking.\"~~\n",
    "\n",
    "Here was my final code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fc1d70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335, 221, 623, 1142, 1, 7, 492, 31, 449, 4, 322, 489, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 31, 1, 1, 2, 418, 161, 441, 1, 186, 1, 1, 1, 1, 13, 1, 0, 1, 1, 2, 1, 1, 4, 1, 1, 1, 1, 1, 1, 322, 0, 1, 31, 174, 1, 0, 0, 136, 97, 152, 52, 627, 1, 139, 321, 618, 39, 332, 239, 1, 1, 1, 14, 1, 1, 605, 1, 644, 3, 1, 3, 781, 1, 1, 1, 1, 1, 1, 12, 1, 1, 9, 151, 10, 1, 342, 1, 1, 1, 1, 1, 1, 1, 31, 15, 643, 1, 1, 1, 1, 1, 654, 7, 738, 1254, 1, 30, 1, 11, 4, 326, 13, 10, 161, 12, 1, 0, 10, 580, 469, 157, 291, 442, 450, 640, 1, 1, 52, 932, 808, 782, 1, 1, 1, 168, 51, 72, 763, 1, 1, 624, 1374, 327, 65, 1, 1048, 657, 1, 1, 1, 1, 67, 0, 321, 168, 691, 1, 1, 1, 1, 1, 1, 171, 1, 1, 1, 1, 1, 1, 1, 489, 1, 31, 1, 388, 1, 1, 143, 352, 0, 1, 462, 1, 170, 712, 493, 181, 400, 795, 1, 211, 2, 2, 2026, 1, 10, 1, 235, 257, 1280, 1, 1, 227, 576, 1, 1, 1, 72, 235, 223, 1, 1, 1, 171, 1, 135, 1, 1, 550, 126, 464, 256, 31, 387, 1, 1, 1, 1, 9, 10, 1, 1, 1, 1, 1, 1, 1, 1, 16, 176, 422, 190, 1, 487, 357, 100, 317, 349, 271, 124, 379, 1, 306, 505, 473, 811, 171, 1, 280, 1, 7, 1, 521, 120, 161, 429, 144, 182, 144, 1, 1, 11, 38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 906, 1, 0, 1, 1, 1, 1, 130, 822, 2, 612, 248, 1, 1, 536, 2, 1, 213, 1, 1, 1, 1, 63, 146, 145, 206, 257, 236, 619, 43, 1, 274, 1, 1, 1, 120, 31, 1, 131, 237, 0, 255, 1, 2, 1, 22, 571, 1, 1064, 13, 1, 1, 1, 10, "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>bias</th>\n",
       "      <th>factuality</th>\n",
       "      <th>owner</th>\n",
       "      <th>source</th>\n",
       "      <th>owner_type</th>\n",
       "      <th>source_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greece legalises sex marriage</td>\n",
       "      <td>Greece ha become the first Christian Orthodox ...</td>\n",
       "      <td>Center</td>\n",
       "      <td>High Factuality</td>\n",
       "      <td>Government of the United Kingdom</td>\n",
       "      <td>https://www.bbc.co.uk/news/world-europe-683101...</td>\n",
       "      <td>Government</td>\n",
       "      <td>legalises same sex marriagePublished1 day agoS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greece becomes first Orthodox Christian countr...</td>\n",
       "      <td>Lawmakers in the 300 seat parliament voted for...</td>\n",
       "      <td>Lean Left</td>\n",
       "      <td>Mixed Factuality</td>\n",
       "      <td>Scott Trust Limited</td>\n",
       "      <td>https://www.theguardian.com/world/2024/feb/15/...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>becomes first Christian Orthodox country to le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greece legalises sex marriage landmark change</td>\n",
       "      <td>The law give same sex couple the right to wed ...</td>\n",
       "      <td>Lean Left</td>\n",
       "      <td>High Factuality</td>\n",
       "      <td>The Hindu Group</td>\n",
       "      <td>https://www.thehindu.com/news/international/gr...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Greece legalises same sex marriage in landmark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Greece becomes first Orthodox Christian countr...</td>\n",
       "      <td>Greece ha become the first Orthodox Christian ...</td>\n",
       "      <td>Center</td>\n",
       "      <td>High Factuality</td>\n",
       "      <td>Bell Media</td>\n",
       "      <td>https://www.ctvnews.ca/world/greece-becomes-fi...</td>\n",
       "      <td>Media Conglomerate</td>\n",
       "      <td>Greece becomes first Orthodox Christian countr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greece legalises sex marriage   another Orthod...</td>\n",
       "      <td>Greece ha become the first majority Orthodox C...</td>\n",
       "      <td>Lean Left</td>\n",
       "      <td>Mixed Factuality</td>\n",
       "      <td>Evgeny Lebedev</td>\n",
       "      <td>https://www.independent.co.uk/news/world/europ...</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Jump to contentUS EditionChangeUK EditionAsia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                      Greece legalises sex marriage   \n",
       "1  Greece becomes first Orthodox Christian countr...   \n",
       "2      Greece legalises sex marriage landmark change   \n",
       "3  Greece becomes first Orthodox Christian countr...   \n",
       "4  Greece legalises sex marriage   another Orthod...   \n",
       "\n",
       "                                             summary       bias  \\\n",
       "0  Greece ha become the first Christian Orthodox ...     Center   \n",
       "1  Lawmakers in the 300 seat parliament voted for...  Lean Left   \n",
       "2  The law give same sex couple the right to wed ...  Lean Left   \n",
       "3  Greece ha become the first Orthodox Christian ...     Center   \n",
       "4  Greece ha become the first majority Orthodox C...  Lean Left   \n",
       "\n",
       "         factuality                             owner  \\\n",
       "0   High Factuality  Government of the United Kingdom   \n",
       "1  Mixed Factuality               Scott Trust Limited   \n",
       "2   High Factuality                   The Hindu Group   \n",
       "3   High Factuality                        Bell Media   \n",
       "4  Mixed Factuality                    Evgeny Lebedev   \n",
       "\n",
       "                                              source          owner_type  \\\n",
       "0  https://www.bbc.co.uk/news/world-europe-683101...          Government   \n",
       "1  https://www.theguardian.com/world/2024/feb/15/...         Independent   \n",
       "2  https://www.thehindu.com/news/international/gr...         Independent   \n",
       "3  https://www.ctvnews.ca/world/greece-becomes-fi...  Media Conglomerate   \n",
       "4  https://www.independent.co.uk/news/world/europ...          Individual   \n",
       "\n",
       "                                         source_text  \n",
       "0  legalises same sex marriagePublished1 day agoS...  \n",
       "1  becomes first Christian Orthodox country to le...  \n",
       "2  Greece legalises same sex marriage in landmark...  \n",
       "3  Greece becomes first Orthodox Christian countr...  \n",
       "4   Jump to contentUS EditionChangeUK EditionAsia...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#Here I'm cleaning the Ground News articles to form a cleaned corpus.\n",
    "#My main task here is using the Ground News summary for each article to remove \n",
    "#superfluous words from the article's source text.\n",
    "#My plan is:\n",
    "#1. Split the source text and summary into word lists and lemmatize them (while maintaining duplicates, stop words, and word order)\n",
    "#2. Remove all stop words from the summary word list\n",
    "#3. Find the first and last indices of words in the source text which match a word in the summary word list\n",
    "#4. Throw out all source text words which fall outside of those indices.\n",
    "#This should hopefully remove all of the ads which were displayed before and after the main story, while keeping the bulk of the main\n",
    "#story for each source text article.\n",
    "df = pd.read_csv('../data/groundnews_corpus_raw.csv',index_col=0).fillna('')\n",
    "wnl = WordNetLemmatizer()\n",
    "junk = re.compile('[^a-zA-Z\\\\d]')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#I tried vectorizing separate functions for each step of this process, but pandas\n",
    "#and numpy don't like the intermediate state of having three columns of the dataframe\n",
    "#be columns with a list in each cell. So instead I'm combining all steps into one function which\n",
    "#will return the cleaned title, summary, and source text. Then I'll vectorize it and run it across the\n",
    "#data frame.\n",
    "\n",
    "#Helper function for lemmatizing a text and returning the lemmatized word list\n",
    "def lemmatize(text):\n",
    "    word_list = re.split(junk,text)\n",
    "    word_list = [re.sub(junk,'',word) for word in word_list]\n",
    "    word_list = [wnl.lemmatize(word) for word in word_list]\n",
    "    return word_list\n",
    "\n",
    "#I tried filtering on the title as well as the summary, and filtering on the title gave me much better results.\n",
    "def clean_source_text(t,s,s_t):\n",
    "    #Step 1\n",
    "    t=lemmatize(t)\n",
    "    s=lemmatize(s)\n",
    "    s_t=lemmatize(s_t)\n",
    "\n",
    "    #Step 2\n",
    "    t = [w for w in t if not w.lower() in stop_words]\n",
    "    \n",
    "    #Step 3\n",
    "    t_in_s_t = [w in t for w in s_t]\n",
    "    # s_in_s_t = [w in s for w in s_t]\n",
    "    \n",
    "    title_matching_indices = [i for i,x in enumerate(t_in_s_t) if x]\n",
    "    # summary_matching_indices = [i for i,x in enumerate(s_in_s_t) if x]\n",
    "    \n",
    "    title = ' '.join(t)\n",
    "    summary = ' '.join(s)\n",
    "    #Step 4\n",
    "    if len(title_matching_indices)>1:\n",
    "        source_text = s_t[title_matching_indices[0]:title_matching_indices[-1]]\n",
    "    # elif len(summary_matching_indices)>1:\n",
    "    #     source_text = s_t[summary_matching_indices[0]:summary_matching_indices[-1]]\n",
    "    else:\n",
    "        source_text = ['']\n",
    "    #Printing out how many junk words were removed by this process for each entry in the corpus.\n",
    "    print(len(s_t)-len(source_text), end=\", \")\n",
    "    \n",
    "    source_text = ' '.join(source_text)\n",
    "    \n",
    "    return title, summary, source_text\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df.loc[i,'title'],df.loc[i,'summary'],df.loc[i,'source_text'] = clean_source_text(\n",
    "        df.loc[i,'title'],df.loc[i,'summary'],df.loc[i,'source_text'])\n",
    "\n",
    "#df.to_csv('../../data/groundnews_corpus_cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49516107",
   "metadata": {},
   "source": [
    "As you can see, this method removed a fair number of 'junk' from many of these source_text entries. For many entries, it barely removed anything, but that's okay. The hope is that as a result of this cleaning, the quality of the remaining source text data will go up significantly, and we can use it for further analysis.\n",
    "\n",
    "After cleaning the source_text with the lemmatized version of the titles, I decide to create a stemmed version in case that might prove better for creating word-document matrices. Here was my code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13248d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>bias</th>\n",
       "      <th>factuality</th>\n",
       "      <th>owner</th>\n",
       "      <th>source</th>\n",
       "      <th>owner_type</th>\n",
       "      <th>source_text</th>\n",
       "      <th>title_s</th>\n",
       "      <th>summary_s</th>\n",
       "      <th>source_text_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greece legalises sex marriage</td>\n",
       "      <td>Greece ha become the first Christian Orthodox ...</td>\n",
       "      <td>Center</td>\n",
       "      <td>High Factuality</td>\n",
       "      <td>Government of the United Kingdom</td>\n",
       "      <td>https://www.bbc.co.uk/news/world-europe-683101...</td>\n",
       "      <td>Government</td>\n",
       "      <td>legalises same sex marriagePublished1 day agoS...</td>\n",
       "      <td>greec legalis sex marriag</td>\n",
       "      <td>greec ha becom the first christian orthodox ma...</td>\n",
       "      <td>legalis same sex marriagepublished1 day agosha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greece becomes first Orthodox Christian countr...</td>\n",
       "      <td>Lawmakers in the 300 seat parliament voted for...</td>\n",
       "      <td>Lean Left</td>\n",
       "      <td>Mixed Factuality</td>\n",
       "      <td>Scott Trust Limited</td>\n",
       "      <td>https://www.theguardian.com/world/2024/feb/15/...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>becomes first Christian Orthodox country to le...</td>\n",
       "      <td>greec becom first orthodox christian countri l...</td>\n",
       "      <td>lawmak in the 300 seat parliament vote for the...</td>\n",
       "      <td>becom first christian orthodox countri to lega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greece legalises sex marriage landmark change</td>\n",
       "      <td>The law give same sex couple the right to wed ...</td>\n",
       "      <td>Lean Left</td>\n",
       "      <td>High Factuality</td>\n",
       "      <td>The Hindu Group</td>\n",
       "      <td>https://www.thehindu.com/news/international/gr...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Greece legalises same sex marriage in landmark...</td>\n",
       "      <td>greec legalis sex marriag landmark chang</td>\n",
       "      <td>the law give same sex coupl the right to wed a...</td>\n",
       "      <td>greec legalis same sex marriag in landmark cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Greece becomes first Orthodox Christian countr...</td>\n",
       "      <td>Greece ha become the first Orthodox Christian ...</td>\n",
       "      <td>Center</td>\n",
       "      <td>High Factuality</td>\n",
       "      <td>Bell Media</td>\n",
       "      <td>https://www.ctvnews.ca/world/greece-becomes-fi...</td>\n",
       "      <td>Media Conglomerate</td>\n",
       "      <td>Greece becomes first Orthodox Christian countr...</td>\n",
       "      <td>greec becom first orthodox christian countri l...</td>\n",
       "      <td>greec ha becom the first orthodox christian co...</td>\n",
       "      <td>greec becom first orthodox christian countri t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greece legalises sex marriage   another Orthod...</td>\n",
       "      <td>Greece ha become the first majority Orthodox C...</td>\n",
       "      <td>Lean Left</td>\n",
       "      <td>Mixed Factuality</td>\n",
       "      <td>Evgeny Lebedev</td>\n",
       "      <td>https://www.independent.co.uk/news/world/europ...</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Jump to contentUS EditionChangeUK EditionAsia...</td>\n",
       "      <td>greec legalis sex marriag   anoth orthodox chr...</td>\n",
       "      <td>greec ha becom the first major orthodox christ...</td>\n",
       "      <td>jump to contentu editionchangeuk editionasia ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                      Greece legalises sex marriage   \n",
       "1  Greece becomes first Orthodox Christian countr...   \n",
       "2      Greece legalises sex marriage landmark change   \n",
       "3  Greece becomes first Orthodox Christian countr...   \n",
       "4  Greece legalises sex marriage   another Orthod...   \n",
       "\n",
       "                                             summary       bias  \\\n",
       "0  Greece ha become the first Christian Orthodox ...     Center   \n",
       "1  Lawmakers in the 300 seat parliament voted for...  Lean Left   \n",
       "2  The law give same sex couple the right to wed ...  Lean Left   \n",
       "3  Greece ha become the first Orthodox Christian ...     Center   \n",
       "4  Greece ha become the first majority Orthodox C...  Lean Left   \n",
       "\n",
       "         factuality                             owner  \\\n",
       "0   High Factuality  Government of the United Kingdom   \n",
       "1  Mixed Factuality               Scott Trust Limited   \n",
       "2   High Factuality                   The Hindu Group   \n",
       "3   High Factuality                        Bell Media   \n",
       "4  Mixed Factuality                    Evgeny Lebedev   \n",
       "\n",
       "                                              source          owner_type  \\\n",
       "0  https://www.bbc.co.uk/news/world-europe-683101...          Government   \n",
       "1  https://www.theguardian.com/world/2024/feb/15/...         Independent   \n",
       "2  https://www.thehindu.com/news/international/gr...         Independent   \n",
       "3  https://www.ctvnews.ca/world/greece-becomes-fi...  Media Conglomerate   \n",
       "4  https://www.independent.co.uk/news/world/europ...          Individual   \n",
       "\n",
       "                                         source_text  \\\n",
       "0  legalises same sex marriagePublished1 day agoS...   \n",
       "1  becomes first Christian Orthodox country to le...   \n",
       "2  Greece legalises same sex marriage in landmark...   \n",
       "3  Greece becomes first Orthodox Christian countr...   \n",
       "4   Jump to contentUS EditionChangeUK EditionAsia...   \n",
       "\n",
       "                                             title_s  \\\n",
       "0                          greec legalis sex marriag   \n",
       "1  greec becom first orthodox christian countri l...   \n",
       "2           greec legalis sex marriag landmark chang   \n",
       "3  greec becom first orthodox christian countri l...   \n",
       "4  greec legalis sex marriag   anoth orthodox chr...   \n",
       "\n",
       "                                           summary_s  \\\n",
       "0  greec ha becom the first christian orthodox ma...   \n",
       "1  lawmak in the 300 seat parliament vote for the...   \n",
       "2  the law give same sex coupl the right to wed a...   \n",
       "3  greec ha becom the first orthodox christian co...   \n",
       "4  greec ha becom the first major orthodox christ...   \n",
       "\n",
       "                                       source_text_s  \n",
       "0  legalis same sex marriagepublished1 day agosha...  \n",
       "1  becom first christian orthodox countri to lega...  \n",
       "2  greec legalis same sex marriag in landmark cha...  \n",
       "3  greec becom first orthodox christian countri t...  \n",
       "4   jump to contentu editionchangeuk editionasia ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "ground_news = pd.read_csv('../data/groundnews_corpus_cleaned.csv',index_col=0).fillna('')\n",
    "junk = re.compile('[^a-zA-Z\\\\d]')\n",
    "\n",
    "#slice the text into words and stem each word\n",
    "def stem(text):\n",
    "    word_list = re.split(' ',text)\n",
    "    word_list = word_list = [re.sub(junk,'',word) for word in word_list]\n",
    "    word_list = [ps.stem(word) for word in word_list]\n",
    "    return ' '.join(word_list)\n",
    "\n",
    "v_stem = np.vectorize(stem)\n",
    "\n",
    "#Add columns for stemmed version of title, summary, and source text.\n",
    "ground_news.loc[:,'title_s'] = v_stem(ground_news.loc[:,'title'])\n",
    "ground_news.loc[:,'summary_s'] = v_stem(ground_news.loc[:,'summary'])\n",
    "ground_news.loc[:,'source_text_s'] = v_stem(ground_news.loc[:,'source_text'])\n",
    "\n",
    "#ground_news.to_csv('../../data/groundnews_corpus_cleaned.csv')\n",
    "ground_news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d35ab5",
   "metadata": {},
   "source": [
    "### And with that, I had cleaned corpuses! Now to create some word-document matrices...\n",
    "\n",
    "# WDMS\n",
    "\n",
    "For this stage of cleaning, I might have gotten a bit overzealous. There were so many options for customization when creating a word-document matrix that I really wasn't sure which I should use. The choices to consider included:\n",
    "\n",
    "1. Which text column from each corpus should I use (title, summary, source text)?\n",
    "2. Stemmed or lemmatized versions of the text?\n",
    "3. Should I remove stop-words?\n",
    "4. Should I use CountVectorizer or TfidfVectorizer?\n",
    "5. How many words should I count as 1 token? (i.e. which value of *n* for n-grams should I be using?)\n",
    "\n",
    "Considering all of these options, I realized I wouldn't know the correct answer to any of them unless I came to that answer through trial an error. So I decided to use pretty much all options. This resulted in me creating not 1, but ***20*** word-document matrices, each stored in their own special location within the now vast ```/data/wdms``` folder tree. I eventually settled on creating one WDM for each text/title column of each API, with stemming/lemming, and count/tfidf.\n",
    "\n",
    "Here was my code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b05d364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>factuality</th>\n",
       "      <th>owner</th>\n",
       "      <th>source</th>\n",
       "      <th>owner_type</th>\n",
       "      <th>transgender</th>\n",
       "      <th>trans</th>\n",
       "      <th>gender</th>\n",
       "      <th>lgbtq</th>\n",
       "      <th>sex</th>\n",
       "      <th>...</th>\n",
       "      <th>program</th>\n",
       "      <th>horrendous</th>\n",
       "      <th>headline</th>\n",
       "      <th>hamilton</th>\n",
       "      <th>sue</th>\n",
       "      <th>criticize</th>\n",
       "      <th>surfer</th>\n",
       "      <th>create</th>\n",
       "      <th>target</th>\n",
       "      <th>abusing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Center</td>\n",
       "      <td>High Factuality</td>\n",
       "      <td>Government of the United Kingdom</td>\n",
       "      <td>https://www.bbc.co.uk/news/world-europe-683101...</td>\n",
       "      <td>Government</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lean Left</td>\n",
       "      <td>Mixed Factuality</td>\n",
       "      <td>Scott Trust Limited</td>\n",
       "      <td>https://www.theguardian.com/world/2024/feb/15/...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lean Left</td>\n",
       "      <td>High Factuality</td>\n",
       "      <td>The Hindu Group</td>\n",
       "      <td>https://www.thehindu.com/news/international/gr...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Center</td>\n",
       "      <td>High Factuality</td>\n",
       "      <td>Bell Media</td>\n",
       "      <td>https://www.ctvnews.ca/world/greece-becomes-fi...</td>\n",
       "      <td>Media Conglomerate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lean Left</td>\n",
       "      <td>Mixed Factuality</td>\n",
       "      <td>Evgeny Lebedev</td>\n",
       "      <td>https://www.independent.co.uk/news/world/europ...</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bias        factuality                             owner  \\\n",
       "0     Center   High Factuality  Government of the United Kingdom   \n",
       "1  Lean Left  Mixed Factuality               Scott Trust Limited   \n",
       "2  Lean Left   High Factuality                   The Hindu Group   \n",
       "3     Center   High Factuality                        Bell Media   \n",
       "4  Lean Left  Mixed Factuality                    Evgeny Lebedev   \n",
       "\n",
       "                                              source          owner_type  \\\n",
       "0  https://www.bbc.co.uk/news/world-europe-683101...          Government   \n",
       "1  https://www.theguardian.com/world/2024/feb/15/...         Independent   \n",
       "2  https://www.thehindu.com/news/international/gr...         Independent   \n",
       "3  https://www.ctvnews.ca/world/greece-becomes-fi...  Media Conglomerate   \n",
       "4  https://www.independent.co.uk/news/world/europ...          Individual   \n",
       "\n",
       "   transgender  trans  gender  lgbtq  sex  ...  program  horrendous  headline  \\\n",
       "0            0      0       0      0    1  ...        0           0         0   \n",
       "1            0      0       0      0    1  ...        0           0         0   \n",
       "2            0      0       0      0    1  ...        0           0         0   \n",
       "3            0      0       0      0    1  ...        0           0         0   \n",
       "4            0      0       0      0    1  ...        0           0         0   \n",
       "\n",
       "   hamilton  sue  criticize  surfer  create  target  abusing  \n",
       "0         0    0          0       0       0       0        0  \n",
       "1         0    0          0       0       0       0        0  \n",
       "2         0    0          0       0       0       0        0  \n",
       "3         0    0          0       0       0       0        0  \n",
       "4         0    0          0       0       0       0        0  \n",
       "\n",
       "[5 rows x 258 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "news = pd.read_csv('../data/newsapi_corpus_cleaned.csv').fillna('')\n",
    "world_news = pd.read_csv('../data/worldnewsapi_corpus_cleaned.csv').fillna('')\n",
    "ground_news = pd.read_csv('../data/groundnews_corpus_cleaned.csv',index_col=0).fillna('')\n",
    "\n",
    "\n",
    "#Extract the metadata, we'll add it back in later\n",
    "news_metadata = news.loc[:,('author','publishedAt','source','url','urlToImage')]\n",
    "world_news_metadata = world_news.loc[:,('authors','country','sentiment','url')]\n",
    "ground_news_metadata = ground_news.loc[:,('bias','factuality','owner','source','owner_type')]\n",
    "\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "cv_2 = CountVectorizer(stop_words='english',ngram_range=(2,2))\n",
    "tv = TfidfVectorizer(stop_words='english')\n",
    "tv_2 = TfidfVectorizer(stop_words='english',ngram_range=(2,2))\n",
    "\n",
    "#This function transforms the text into a word-document matrix containing all words\n",
    "#which occur at least twice (this is to cut down on size, under the assumption that the words which occur\n",
    "#once are more trouble than they're worth), and sorts the matrix based on frequency.\n",
    "def create_wdm(series,metadata,cv,n):\n",
    "    wdm = cv.fit_transform(series)\n",
    "    wdm_df = pd.DataFrame(data=wdm.toarray(),columns=cv.get_feature_names_out())\n",
    "    wdm_df.loc['sum'] = wdm_df.sum()\n",
    "    #Filter for words with a minimum frequency. Cuts down on junk and size\n",
    "    wdm_df = wdm_df.loc[:,wdm_df.loc['sum']>n]\n",
    "    #filter for strings greater than a certain length. Cuts out some silliness.\n",
    "    wdm_df = wdm_df.filter(regex=r'^[a-zA-Z]{3,}$')\n",
    "    wdm_df = wdm_df.sort_values(by='sum',axis=1,ascending=False)\n",
    "    wdm_df = pd.concat([metadata,wdm_df],axis=1,join='inner')\n",
    "    return wdm_df\n",
    "\n",
    "#Create the WDMs for News. Altering min number of occurances to keep the size of larger WDMs in check.\n",
    "# news_title_l_cv = create_wdm(news['title_l'], news_metadata, cv, 3)\n",
    "# news_desc_l_cv = create_wdm(news['desc_l'], news_metadata, cv, 3)\n",
    "# news_content_l_cv = create_wdm(news['content_l'], news_metadata, cv, 3)\n",
    "# news_title_l_tv = create_wdm(news['title_l'], news_metadata, tv, 3)\n",
    "# news_desc_l_tv = create_wdm(news['desc_l'], news_metadata, tv, 3)\n",
    "# news_content_l_tv = create_wdm(news['content_l'], news_metadata, tv, 3)\n",
    "\n",
    "# news_title_s_cv = create_wdm(news['title_s'], news_metadata, cv, 3)\n",
    "# news_desc_s_cv = create_wdm(news['desc_s'], news_metadata, cv, 3)\n",
    "# news_content_s_cv = create_wdm(news['content_s'], news_metadata, cv, 3)\n",
    "# news_title_s_tv = create_wdm(news['title_s'], news_metadata, tv, 3)\n",
    "# news_desc_s_tv = create_wdm(news['desc_s'], news_metadata, tv, 3)\n",
    "# news_content_s_tv = create_wdm(news['content_s'], news_metadata, tv, 3)\n",
    "\n",
    "\n",
    "#Create the WDMs for World News\n",
    "# world_news_title_s_cv = create_wdm(world_news['title_s'], world_news_metadata, cv, 6)\n",
    "# world_news_text_s_cv = create_wdm(world_news['text_s'], world_news_metadata, cv, 15)\n",
    "# world_news_title_s_tv = create_wdm(world_news['title_s'], world_news_metadata, tv, 6)\n",
    "# world_news_text_s_tv = create_wdm(world_news['text_s'], world_news_metadata, tv, 15)\n",
    "\n",
    "# world_news_title_l_cv = create_wdm(world_news['title_l'], world_news_metadata, cv, 6)\n",
    "# world_news_text_l_cv = create_wdm(world_news['text_l'], world_news_metadata, cv, 15)\n",
    "# world_news_title_l_tv = create_wdm(world_news['title_l'], world_news_metadata, tv, 6)\n",
    "# world_news_text_l_tv = create_wdm(world_news['text_l'], world_news_metadata, tv, 15)\n",
    "\n",
    "#Create the WDMs for Ground News\n",
    "\n",
    "ground_news_title_l_cv = create_wdm(ground_news['title'], ground_news_metadata, cv, 3)\n",
    "# ground_news_title_l_tv = create_wdm(ground_news['title'], ground_news_metadata, tv, 3)\n",
    "# ground_news_title_s_cv = create_wdm(ground_news['title_s'], ground_news_metadata, cv, 3)\n",
    "# ground_news_title_s_tv = create_wdm(ground_news['title_s'], ground_news_metadata, tv, 3)\n",
    "\n",
    "# ground_news_summary_l_cv = create_wdm(ground_news['summary'], ground_news_metadata, cv, 3)\n",
    "# ground_news_summary_l_tv = create_wdm(ground_news['summary'], ground_news_metadata, tv, 3)\n",
    "# ground_news_summary_s_cv = create_wdm(ground_news['summary_s'], ground_news_metadata, cv, 3)\n",
    "# ground_news_summary_s_tv = create_wdm(ground_news['summary_s'], ground_news_metadata, tv, 3)\n",
    "\n",
    "# ground_news_source_text_l_cv = create_wdm(ground_news['source_text'], ground_news_metadata, cv, 3)\n",
    "# ground_news_source_text_l_tv = create_wdm(ground_news['source_text'], ground_news_metadata, tv, 3)\n",
    "# ground_news_source_text_s_cv = create_wdm(ground_news['source_text_s'], ground_news_metadata, cv, 3)\n",
    "# ground_news_source_text_s_tv = create_wdm(ground_news['source_text_s'], ground_news_metadata, tv, 3)\n",
    "\n",
    "#Saving WDMs to csv.\n",
    "# news_title_s_cv.to_csv('../../data/wdms/count/newsapi/stemmed/title.csv')\n",
    "# news_desc_s_cv.to_csv('../../data/wdms/count/newsapi/stemmed/desc.csv')\n",
    "# news_content_s_cv.to_csv('../../data/wdms/count/newsapi/stemmed/content.csv')\n",
    "# news_title_s_tv.to_csv('../../data/wdms/tfidf/newsapi/stemmed/title.csv')\n",
    "# news_desc_s_tv.to_csv('../../data/wdms/tfidf/newsapi/stemmed/desc.csv')\n",
    "# news_content_s_tv.to_csv('../../data/wdms/tfidf/newsapi/stemmed/content.csv')\n",
    "\n",
    "# news_title_l_cv.to_csv('../../data/wdms/count/newsapi/lemmed/title.csv')\n",
    "# news_desc_l_cv.to_csv('../../data/wdms/count/newsapi/lemmed/desc.csv')\n",
    "# news_content_l_cv.to_csv('../../data/wdms/count/newsapi/lemmed/content.csv')\n",
    "# news_title_l_tv.to_csv('../../data/wdms/tfidf/newsapi/lemmed/title.csv')\n",
    "# news_desc_l_tv.to_csv('../../data/wdms/tfidf/newsapi/lemmed/desc.csv')\n",
    "# news_content_l_tv.to_csv('../../data/wdms/tfidf/newsapi/lemmed/content.csv')\n",
    "\n",
    "\n",
    "# world_news_title_s_cv.to_csv('../../data/wdms/count/worldnewsapi/stemmed/title.csv')\n",
    "# world_news_text_s_cv.to_csv('../../data/wdms/count/worldnewsapi/stemmed/text.csv')\n",
    "# world_news_title_l_cv.to_csv('../../data/wdms/count/worldnewsapi/lemmed/title.csv')\n",
    "# world_news_text_l_cv.to_csv('../../data/wdms/count/worldnewsapi/lemmed/text.csv')\n",
    "\n",
    "# world_news_title_s_cv.to_csv('../../data/wdms/tfidf/worldnewsapi/stemmed/title.csv')\n",
    "# world_news_text_s_cv.to_csv('../../data/wdms/tfidf/worldnewsapi/stemmed/text.csv')\n",
    "# world_news_title_l_cv.to_csv('../../data/wdms/tfidf/worldnewsapi/lemmed/title.csv')\n",
    "# world_news_text_l_cv.to_csv('../../data/wdms/tfidf/worldnewsapi/lemmed/title.csv')\n",
    "\n",
    "\n",
    "# ground_news_title_s_cv.to_csv('../../data/wdms/count/groundnews/stemmed/title.csv')\n",
    "# ground_news_summary_s_cv.to_csv('../../data/wdms/count/groundnews/stemmed/summ.csv')\n",
    "# ground_news_source_text_s_cv.to_csv('../../data/wdms/count/groundnews/stemmed/source.csv')\n",
    "# ground_news_title_s_tv.to_csv('../../data/wdms/tfidf/groundnews/stemmed/title.csv')\n",
    "# ground_news_summary_s_tv.to_csv('../../data/wdms/tfidf/groundnews/stemmed/summ.csv')\n",
    "# ground_news_source_text_s_tv.to_csv('../../data/wdms/tfidf/groundnews/stemmed/source.csv')\n",
    "\n",
    "# ground_news_title_l_cv.to_csv('../../data/wdms/count/groundnews/lemmed/title.csv')\n",
    "# ground_news_summary_l_cv.to_csv('../../data/wdms/count/groundnews/lemmed/summ.csv')\n",
    "# ground_news_source_text_l_cv.to_csv('../../data/wdms/count/groundnews/lemmed/source.csv')\n",
    "# ground_news_title_l_tv.to_csv('../../data/wdms/tfidf/groundnews/lemmed/title.csv')\n",
    "# ground_news_summary_l_tv.to_csv('../../data/wdms/tfidf/groundnews/lemmed/summ.csv')\n",
    "# ground_news_source_text_l_tv.to_csv('../../data/wdms/tfidf/groundnews/lemmed/source.csv')\n",
    "\n",
    "ground_news_title_l_cv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c6e45",
   "metadata": {},
   "source": [
    "I'm breaking with tradition here and only showing the output for the creation of one of the many word-document matrices. Of all the code I've showed off so far, this program had the highest preponderance to cause memory crashes, so for demonstration purposes I'm going to keep it light.\n",
    "\n",
    "Essentially, I used the various vectorizers to create word-document matrices, then organized those matrices based on word frequency, and used a minimum frequency cut-off to remove junk words that only appeared once or twice. I always removed stopwords, after finding that not removing stop-words resulted in a lot of unnecessary junk at the top of my WDMs. I'm also sticking with *n=1* for the purposes of n-grams for now, because with *n=2* this function often resulted in a memory crash.\n",
    "\n",
    "The resulting WDMs are going to form the basis for further analysis, which you can check out in the exploratory analysis tab."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
